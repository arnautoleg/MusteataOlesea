---
title: "CI"
author: "Oleg Arnaut"
date: "2023-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)


```

# Точечные оценки

## Описательные статистики для количественных переменных

```{r}

# Создаем набор данных
data <- c(15, 23, 17, 32, 19, 25, 21, 28, 14, 30)

# Среднее арифметическое (Mean)
mean_value <- mean(data)

# Медиана (Median)
median_value <- median(data)

# Мода (Mode) - для дискретных данных
mode_value <- as.numeric(names(sort(table(data), decreasing = TRUE)[1]))

# Минимум и максимум (Range)
min_value <- min(data)
max_value <- max(data)

# Стандартное отклонение (Standard Deviation)
sd_value <- sd(data)

# Дисперсия (Variance)
variance_value <- var(data)

# Размах (Range)
range_value <- max_value - min_value

# Квантили (Quantiles)
quantiles <- quantile(data, probs = c(0.25, 0.5, 0.75))

# Вывод результатов
cat("Среднее:", mean_value, "\n")
cat("Медиана:", median_value, "\n")
cat("Мода:", mode_value, "\n")
cat("Минимум:", min_value, "\n")
cat("Максимум:", max_value, "\n")
cat("Стандартное отклонение:", sd_value, "\n")
cat("Дисперсия:", variance_value, "\n")
cat("Размах:", range_value, "\n")
cat("25-й квантиль:", quantiles[1], "\n")
cat("50-й квантиль (медиана):", quantiles[2], "\n")
cat("75-й квантиль:", quantiles[3], "\n")



```


## Описательные статистики для категориальных переменных


```{r}

# Создаем набор данных для категориальной переменной
data <- c("Категория A", "Категория B", "Категория A", "Категория C", "Категория B", "Категория A", "Категория A", "Категория B")

# Частота (Frequency)
frequency_table <- table(data)
cat("Частота каждой категории:\n")
print(frequency_table)
cat("\n")

# Относительная частота (Relative Frequency)
relative_frequency <- prop.table(frequency_table)
cat("Относительная частота каждой категории:\n")
print(relative_frequency)
cat("\n")

```


## Описательные статистики для порядковых переменных


```{r}

# Создаем набор данных для порядковой переменной
data <- c("Низкий", "Средний", "Высокий", "Средний", "Средний", "Низкий", "Высокий", "Средний")

# Частота (Frequency)
frequency_table <- table(data)
cat("Частота каждой категории:\n")
print(frequency_table)
cat("\n")

# Относительная частота (Relative Frequency)
relative_frequency <- prop.table(frequency_table)
cat("Относительная частота каждой категории:\n")
print(relative_frequency)
cat("\n")

# Медиана (Median)
# Соответствие между порядковыми значениями и числами
ordered_values <- c("Низкий" = 1, "Средний" = 2, "Высокий" = 3)
numeric_data <- ordered_values[data]

median_value <- median(numeric_data)
cat("Медиана:", median_value, "\n")

```


## Зачем нужна визуализация?

```{r, fig.width=10, fig.height=5}


# Create a 2x2 layout for the plots
par(mfrow=c(2, 2))


# Set the parameters for the normal distribution
mean_normal <- 50
sd_normal <- 10
# Generate random data for the normal distribution
data_normal <- rnorm(10000, mean = mean_normal, sd = sd_normal)

# Plot Normal Distribution
hist(data_normal, breaks = 30, col = 'blue', main = 'Normal Distribution (μ=50)', xlab = 'Value', ylab = 'Frequency')


# Set the parameters for the uniform distribution
min_uniform <- 44.5
max_uniform <- 55.5

# Generate random data for the uniform distribution
data_uniform <- runif(10000, min = min_uniform, max = max_uniform)


# Plot Uniform Distribution
hist(data_uniform, breaks = 30, col = 'green', main = 'Uniform Distribution (μ=50)', xlab = 'Value', ylab = 'Frequency')


# Set the parameters for the bimodal distribution
mean1_bimodal <- 20
sd1_bimodal <- 10
mean2_bimodal <- 80
sd2_bimodal <- 10

# Generate random data for the bimodal distribution
data_bimodal <- c(rnorm(5000, mean = mean1_bimodal, sd = sd1_bimodal), rnorm(5000, mean = mean2_bimodal, sd = sd2_bimodal))


# Plot Bimodal Distribution
hist(data_bimodal, breaks = 30, col = 'red', main = 'Bimodal Distribution (μ=50)', xlab = 'Value', ylab = 'Frequency')

# Generate data for Exponential Distribution with a similar mean and sd
mean_exp <- 50
sd_exp <- 10
lambda_exp <- 1 / mean_exp

data_exponential <- rexp(10000, rate = lambda_exp)

# Plot Exponential Distribution
hist(data_exponential, breaks = 30, col = 'purple', main = 'Exponential Distribution (μ=50)', xlab = 'Value', ylab = 'Frequency')



# Reset the layout
par(mfrow=c(1, 1))


```


# Доверительные интервалы для среднего

## Квантили (напомнить)

```{r}
# Загрузка необходимого пакета ggplot2
library(ggplot2)


a <- c(0:100)

cat(quantile(a, 0.025), 
    quantile(a, 0.975))

#?quantile


# Создание случайного вектора данных
data <- rnorm(1000000, mean = 0, sd = 1)
data_df <- data.frame(Value = data)


# Создание графика "ящик с усами" для данных
ggplot(data = data_df, aes(x = "", y = Value)) +
  geom_boxplot(fill = "lightblue", color = "blue") +
  labs(x = "", y = "Значение") +
  theme_minimal()


# Преобразование данных в data frame
data_df <- data.frame(Value = data)


percentile1 <- 0.025
percentile2 <- 0.975

# Вычисление q1 и q2 квантилей
q1 <- quantile(data, percentile1)
q2 <- quantile(data, percentile2)

# Создание графика плотности распределения с ggplot2
ggplot(data = data_df, aes(x = Value)) +
  geom_density(fill = "blue", alpha = 0.5) +
  geom_vline(xintercept = c(q1, q2), linetype = "dashed", color = "red") +
  annotate("text", x = q1-0.15, y = 0.3, label = sprintf("Q(%.1f)=%.2f", percentile1*100, q1), hjust = 1, angle = 90) +
  annotate("text", x = q2-0.15, y = 0.2, label = sprintf("Q(%.1f)=%.2f", percentile2*100, q2), hjust = 0, angle = 90) +
  labs(x = "Значение", y = "Плотность") +
  theme_minimal()



```

## От чего зависит ширина доверительного интервала?

```{r}

sample_size <- 300 # Количество пациентов, прошедших, терапию

Hg_improve <- 20 # Истинное среднее изменение уровня Hg (в ГЕНЕРАЛЬНОЙ СОВОКУПНОСТИ)

Hg_sd <- 6 # Разброс в улучшении Hg

df_trial <- data.frame(
  ID = 1:sample_size,
  Hg_change = rnorm(sample_size, mean = Hg_improve, sd = Hg_sd)
)

t.test(df_trial$Hg_change)

trial_results <- df_trial %>% 
  t.test(Hg_change ~ 1, conf.level = 0.95, data = .) %>% 
  broom::tidy() %>% 
  dplyr::select(estimate, conf.low, conf.high) %>% 
  mutate(CI_width = conf.high - conf.low)

trial_results
  
# Что происходит с ДИ при изменении:
# - объема выборки?
# - стандартного отклонения?
# - уровня доверия?

```


## Доверительный интервал для среднего значения


### Асимптотический ДИ - нормальное распределение

```{r}

set.seed(123)

mean = 20
sd = 3
data <- rnorm(10, mean = mean, sd = sd)

# Confidence level
confidence_level <- 0.95

# Sample mean and standard deviation
sample_mean <- mean(data)
sample_sd <- sd(data)

# Sample size
sample_size <- length(data)

# Z-interval
z_critical <- qnorm(1 - (1 - confidence_level) / 2)
margin_of_error <- z_critical * (sample_sd / sqrt(sample_size))
ci_asymptotic <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)

cat("Asymptotic Method (Z-interval):", ci_asymptotic, "Ширина:", ci_asymptotic[2]-ci_asymptotic[1], "\n")

```


### Точный ДИ Дисперсия известна (н-р погрешность прибора) - нормальное распределение


```{r}

set.seed(123)

mean = 20
sd = 3
data <- rnorm(10, mean = mean, sd = sd)

# Confidence level
confidence_level <- 0.95

# Sample mean and standard deviation
sample_mean <- mean(data)
#sample_sd <- sd(data)

# Sample size
sample_size <- length(data)

# Z-interval
z_critical <- qnorm(1 - (1 - confidence_level) / 2)
margin_of_error <- z_critical * (sd / sqrt(sample_size))
ci_exact_z <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)

cat("Exact Method (Z-interval):", ci_exact_z, "Ширина:", ci_exact_z[2]-ci_exact_z[1], "\n")


```

### Точный ДИ Дисперсия неизвестна (распределение chi squared, t, Теорема Фишера - (n-1)*s**2/sigma**2 имеет chi squared распределение с df=n-1) - выборка из нормального распределения

```{r}

set.seed(123)

mean = 20
sd = 3
data <- rnorm(10, mean = mean, sd = sd)

# Confidence level
confidence_level <- 0.95

# Sample mean and standard deviation
sample_mean <- mean(data)
sample_sd <- sd(data)  # Используем стандартное отклонение из выборки
sample_size <- length(data)

t_critical <- qt(1 - (1 - confidence_level) / 2, df = sample_size - 1)
margin_of_error <- t_critical * (sample_sd / sqrt(sample_size))
ci_exact <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)
cat("Exact Method (t-interval):", ci_exact, "Ширина:", ci_exact[2]-ci_exact[1], "\n")



```

### Все вместе

```{r}

cat("Asymptotic Method (Z-interval):", ci_asymptotic, "Ширина:", ci_asymptotic[2]-ci_asymptotic[1], "\n")
cat("Exact Method (Z-interval)     :", ci_exact_z, "Ширина:", ci_exact_z[2]-ci_exact_z[1], "\n")
cat("Exact Method (t-interval)     :", ci_exact,      "Ширина:", ci_exact[2]-ci_exact[1], "\n")


```


### Asymptotic Method (Z-interval) (симуляция)

```{r}

# Начальные параметры
set.seed(123)

mean = 20
sd = 3
confidence_level <- 0.95
sample_size <- 10
num_simulations <- 1000

# Функция для создания доверительного интервала
create_confidence_interval <- function(data, confidence_level, method) {
  sample_mean <- mean(data)
  sample_sd <- sd(data)
  sample_size <- length(data)
  
  if (method == "asymptotic") {
    z_critical <- qnorm(1 - (1 - confidence_level) / 2)
    margin_of_error <- z_critical * (sample_sd / sqrt(sample_size))
  } 
  
  
  ci <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)
  return(ci)
}

# Инициализируем переменные для подсчета количества "ловлений" истинного среднего
asymptotic_captured <- 0


# Цикл для симуляции num_simulations раз
for (i in 1:num_simulations) {
  data <- rnorm(sample_size, mean = mean, sd = sd)
  
  # Рассчитываем доверительные интервалы для каждого метода
  ci_asymptotic <- create_confidence_interval(data, confidence_level, "asymptotic")

  
  # Проверяем, ловит ли доверительный интервал истинное значение среднего
  if (ci_asymptotic[1] <= mean && ci_asymptotic[2] >= mean) {
    asymptotic_captured <- asymptotic_captured + 1
  }
  
  
}

# Выводим результаты
cat("Асимптотический ДИ - доля ловлений истинной разницы    :", asymptotic_captured / num_simulations, "\n")


```



### Сравнительная характеристика Asymptotic Method (Z-interval), Exact Method (Z-intervalt-interval), Exact Method (t-interval) в случае нормального распределения (симуляция)

```{r}

# Начальные параметры
set.seed(123)

mean = 20
sd = 3
confidence_level <- 0.95
sample_size <- 10
num_simulations <- 1000

# Функция для создания доверительного интервала
create_confidence_interval <- function(data, confidence_level, method) {
  sample_mean <- mean(data)
  sample_sd <- sd(data)
  sample_size <- length(data)
  
  if (method == "asymptotic") {
    z_critical <- qnorm(1 - (1 - confidence_level) / 2)
    margin_of_error <- z_critical * (sample_sd / sqrt(sample_size))
  } 
  
  if (method == "exact_z") {
    z_critical <- qnorm(1 - (1 - confidence_level) / 2)
    margin_of_error <- z_critical * (sd / sqrt(sample_size))
  } 
  
  if (method == "exact_t") {
    t_critical <- qt(1 - (1 - confidence_level) / 2, df = sample_size - 1)
    margin_of_error <- t_critical * (sample_sd / sqrt(sample_size))
  } 
  
  
  ci <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)
  return(ci)
}

# Инициализируем переменные для подсчета количества "ловлений" истинного среднего
asymptotic_captured <- 0
exact_z_captured <- 0
exact_t_captured <- 0

# Цикл для симуляции num_simulations раз
for (i in 1:num_simulations) {
  data <- rnorm(sample_size, mean = mean, sd = sd)
  
  # Рассчитываем доверительные интервалы для каждого метода
  ci_asymptotic <- create_confidence_interval(data, confidence_level, "asymptotic")
  ci_exact_z <- create_confidence_interval(data, confidence_level, "exact_z")
  ci_exact_t <- create_confidence_interval(data, confidence_level, "exact_t")
  
  # Проверяем, ловит ли доверительный интервал истинное значение среднего
  if (ci_asymptotic[1] <= mean && ci_asymptotic[2] >= mean) {
    asymptotic_captured <- asymptotic_captured + 1
  }
  
  if (ci_exact_z[1] <= mean && ci_exact_z[2] >= mean) {
    exact_z_captured <- exact_z_captured + 1
  }
  
  if (ci_exact_t[1] <= mean && ci_exact_t[2] >= mean) {
    exact_t_captured <- exact_t_captured + 1
  }
}

# Выводим результаты
cat("Асимптотический ДИ - доля ловлений истинной разницы    :", asymptotic_captured / num_simulations, "\n")
cat("Точный ДИ (Z-интервал) - доля ловлений истинной разницы:", exact_z_captured / num_simulations, "\n")
cat("Точный ДИ (t-интервал) - доля ловлений истинной разницы:", exact_t_captured / num_simulations, "\n")

```

### Пакетная реализация в R

```{r}
library(BSDA)


# Создание данных для одной выборки
set.seed(123)
mean <- 20
sd <- 3
sample_size <- 10
data <- rnorm(sample_size, mean = mean, sd = sd)

# Confidence level
confidence_level <- 0.95

# Асимптотический доверительный интервал для среднего
z_test_result <- z.test(x=data, conf.level = confidence_level, sigma.x = sd(data), mu = mean)
ci_asymptotic <- z_test_result$conf.int
cat("Асимптотический ДИ (Z-interval) для среднего                  :", ci_asymptotic, "\n")

# Точный доверительный интервал для среднего (с известной дисперсией)
z_test_result <- z.test(x=data, conf.level = confidence_level, sigma.x = sd, mu = mean)
ci_exact_z <- z_test_result$conf.int
cat("Точный ДИ (Z-interval) для среднего                           :", ci_exact_z, "\n")


# Точный доверительный интервал для среднего (с неизвестной дисперсией)
ci_exact_unknown_var <- t.test(data, conf.level = confidence_level, var.equal = FALSE)$conf.int
cat("Точный ДИ (t-interval) для среднего (с неизвестной дисперсией):", ci_exact_unknown_var, "\n")


```




### Сравнительная характеристика Asymptotic Method (Z-interval), Exact Method (Z-intervalt-interval), Exact Method (t-interval) в случае экспоненциального распределения (симуляция)


```{r}

# Specify the desired mean and standard deviation
mean <- 10

# Calculate the rate parameter (λ)
lambda <- 1 / mean

# Generate random data from the exponential distribution with the specified λ
data_exponential <- rexp(100, rate = lambda)

# Check the actual mean and standard deviation of the generated data
actual_mean <- mean(data_exponential)
actual_sd <- sd(data_exponential)

# Print the actual mean and standard deviation
cat("Actual Mean:", actual_mean, "\n")
cat("Actual Standard Deviation:", actual_sd, "\n")

hist(data_exponential)


```


```{r}


# Начальные параметры
set.seed(123)

mean = 20
sd = 3
confidence_level <- 0.95
sample_size <- 10
num_simulations <- 1000

# Функция для создания доверительного интервала
create_confidence_interval <- function(data, confidence_level, method) {
  sample_mean <- mean(data)
  sample_sd <- sd(data)
  sample_size <- length(data)
  
  if (method == "asymptotic") {
    z_critical <- qnorm(1 - (1 - confidence_level) / 2)
    margin_of_error <- z_critical * (sample_sd / sqrt(sample_size))
  } 
  
  if (method == "exact_z") {
    z_critical <- qnorm(1 - (1 - confidence_level) / 2)
    margin_of_error <- z_critical * (round(sample_sd, 0) / sqrt(sample_size))
  } 
  
  if (method == "exact_t") {
    t_critical <- qt(1 - (1 - confidence_level) / 2, df = sample_size - 1)
    margin_of_error <- t_critical * (sample_sd / sqrt(sample_size))
  } 
  
  
  ci <- c(sample_mean - margin_of_error, sample_mean + margin_of_error)
  return(ci)
}

# Инициализируем переменные для подсчета количества "ловлений" истинного среднего
asymptotic_captured <- 0
exact_z_captured <- 0
exact_t_captured <- 0

# Цикл для симуляции num_simulations раз
for (i in 1:num_simulations) {
  data <- rexp(sample_size, rate = 1/mean)
  
  # Рассчитываем доверительные интервалы для каждого метода
  ci_asymptotic <- create_confidence_interval(data, confidence_level, "asymptotic")
  ci_exact_z <- create_confidence_interval(data, confidence_level, "exact_z")
  ci_exact_t <- create_confidence_interval(data, confidence_level, "exact_t")
  
  # Проверяем, ловит ли доверительный интервал истинное значение среднего
  if (ci_asymptotic[1] <= mean && ci_asymptotic[2] >= mean) {
    asymptotic_captured <- asymptotic_captured + 1
  }
  
  if (ci_exact_z[1] <= mean && ci_exact_z[2] >= mean) {
    exact_z_captured <- exact_z_captured + 1
  }
  
  if (ci_exact_t[1] <= mean && ci_exact_t[2] >= mean) {
    exact_t_captured <- exact_t_captured + 1
  }
}

# Выводим результаты
cat("Асимптотический ДИ - доля ловлений истинной разницы    :", asymptotic_captured / num_simulations, "\n")
cat("Точный ДИ (Z-интервал) - доля ловлений истинной разницы:", exact_z_captured / num_simulations, "\n")
cat("Точный ДИ (t-интервал) - доля ловлений истинной разницы:", exact_t_captured / num_simulations, "\n")

```



# Доверительный интервал для разницы средних

## Доверительный интервал для разницы средних (независимые выборки)

```{r}

# Воспроизведение данных
set.seed(123)

# Пример данных для двух независимых выборок
mean1 = 20
sd = 3
mean2 = 20
n1 = 10
n2 = 10
data1 <- rnorm(n1, mean = mean1, sd = sd)
data2 <- rnorm(n2, mean = mean2, sd = sd)

# Confidence level
confidence_level <- 0.95

```


### Асимптотический ДИ

```{r}


# Subset the data into two groups based on the 'brick' column
x <- data1
y <- data2

# Calculate the difference in means
diff <- mean(x) - mean(y)

# Sample sizes
nx <- length(x)
ny <- length(y)

# calculate SD
sd_x <- sd(x)
sd_y <- sd(y)

# Calculate the standard error of the difference in means
diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)

# Calculate the 95% confidence interval
z <- qnorm(0.975)  # For a 95% confidence interval
left_a <- diff - z * diff_sd
right_a <- diff + z * diff_sd

# Print the confidence interval
cat("Asymptotic Confidence Interval [", round(left_a, 4), ";", round(right_a, 4), "] Width:", round(right_a - left_a, 4), "\n")



#install.packages("BSDA")  # Uncomment and run this line if you haven't installed the package
library(BSDA)


# Perform the two-sample Z-test

z_test_result <- z.test(x, y, sigma.x = sd(x), sigma.y = sd(y))

# Print the test result
print(z_test_result)

```

### Точный ДИ (Дисперсии извеcтны, разность средних в точности имеет нормальное распределение, итоговая статистика также имеет нормальное z распределение)


```{r}


# Subset the data into two groups based on the 'brick' column
x <- data1
y <- data2

# Calculate the difference in means
diff <- mean(x) - mean(y)

# Sample sizes
nx <- length(x)
ny <- length(y)

# calculate SD
sd_x <- sd
sd_y <- sd

# Calculate the standard error of the difference in means
diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)

# Calculate the 95% confidence interval
z <- qnorm(0.975)  # For a 95% confidence interval
left_t1 <- diff - z * diff_sd
right_t1 <- diff + z * diff_sd

# Print the confidence interval
cat("Exact Confidence Interval with Known Variances [", round(left_t1, 4), ";", round(right_t1, 4), "] Width:", round(right_t1 - left_t1, 4), "\n")


# Perform the two-sample Z-test

z_test_result <- z.test(x, y, sigma.x = sd, sigma.y = sd)

# Print the test result
print(z_test_result)


```


### Точный ДИ (Дисперсии неизвеcтны но равны, статистика Стьюдента - распределение t)


```{r}


# Subset the data into two groups based on the 'brick' column
x <- data1
y <- data2

# Calculate the difference in means
diff <- mean(x) - mean(y)

# Sample sizes
nx <- length(x)
ny <- length(y)

# calculate SD
sd_x <- sd(x)
sd_y <- sd(y)


library(car)
# Perform Levene's test
result <- leveneTest(c(x, y), as.factor(rep(c("Group1", "Group2"), each = nx)))

# Print the test result
print(result)

# Degrees of freedom
df1 <- nx - 1
df2 <- ny - 1

# Calculate the standard error of the difference in means
diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)

# Calculate the 95% confidence interval

t_critical <- qt(1 - (1 - confidence_level) / 2, df1 + df2)

left_t2 <- diff - t_critical * diff_sd
right_t2 <- diff + t_critical * diff_sd

# Print the confidence interval
cat("Exact Confidence Interval with Unknown Variances [", round(left_t2, 4), ";", round(right_t2, 4), "] Width:", round(right_t2 - left_t2, 4), "\n")


t_result <- t.test(x, y, conf.level = 0.95, var.equal = TRUE)
ci_lower <- t_result$conf.int[1]
ci_upper <- t_result$conf.int[2]

cat("Exact Confidence Interval with Unknown Variances [", round(ci_lower, 4), ";", round(ci_upper, 4), "] Width:", round(ci_upper - ci_lower, 4), "\n")

```


### Примерный ДИ (Дисперсии не извеcтны и не равны - получить распределение для такой статистики не представляется возможным - нерешённая проблема статистики (проблема Беренца-Фишера - невозможно точно сравнить средние двух независимых выборок, дисперсии которых неизвестны) - распределение приближённое (распределение Уэлча, работает хорошо если количество наблюдений в группах совпадает или для выборки с большей дисперсией мы собираем больше наблюдений))


```{r}


# Data
x <- data1
y <- data2


# Calculate the difference in means
diff <- mean(x) - mean(y)

# Sample sizes
nx <- length(x)
ny <- length(y)

# calculate SD
sd_x <- sd(x)
sd_y <- sd(y)


# Calculate the standard error of the difference in means
diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)


# Calculate the degrees of freedom (Welch-Satterthwaite approximation)
numerator <- ((sd_x^2 / nx) + (sd_y^2 / n2))^2
denominator <- (sd_x^4 / (nx^2 * (nx - 1))) + (sd_y^4 / (ny^2 * (ny - 1)))

df <- numerator / denominator


# Calculate the 95% confidence interval

t_critical <- qt(1 - (1 - confidence_level) / 2, df)

left_w <- diff - t_critical * diff_sd
right_w <- diff + t_critical * diff_sd

# Print the confidence interval
cat("Confidence Interval by Welch [", round(left_w, 4), ";", round(right_w, 4), "] Width:", round(right_w - left_w, 4), "\n")

t_result <- t.test(x, y, conf.level = 0.95, var.equal = FALSE)
ci_lower <- t_result$conf.int[1]
ci_upper <- t_result$conf.int[2]

cat("Confidence Interval by Welch [", round(ci_lower, 4), ";", round(ci_upper, 4), "] Width:", round(ci_upper - ci_lower, 4), "\n")


```


### Все вместе

```{r}

cat("Asymptotic Confidence Interval                   [", round(left_a, 4), ";", round(right_a, 4), "] Width:", round(right_a - left_a, 4), "\n")
cat("Exact Confidence Interval with Known Variances   [", round(left_t1, 4), ";", round(right_t1, 4), "] Width:", round(right_t1 - left_t1, 4), "\n")
cat("Exact Confidence Interval with Unknown Variances [", round(left_t2, 4), ";", round(right_t2, 4), "] Width:", round(right_t2 - left_t2, 4), "\n")
cat("Confidence Interval by Welch                     [", round(left_w, 4), ";", round(right_w, 4), "] Width:", round(right_w - left_w, 4), "\n")

```



### Сравнительная характеристика (Asymptotic Confidence Interval, Exact Confidence Interval with Known Variances, Exact Confidence Interval with Unknown Variances, Confidence Interval by Welch в случае нормального распределения (независимые группы)

### Средняя ширина ДИ

```{r}

# Воспроизведение данных
set.seed(123)

# Пример данных для двух независимых выборок
mean1 <- 20
sd <- 3
mean2 <- 20
n1 <- 10
n2 <- 10

# Confidence level
confidence_level <- 0.95

# Инициализируем пустые векторы для хранения результатов
asymptotic_intervals <- matrix(nrow = 1000, ncol = 2)
exact_known_variance_intervals <- matrix(nrow = 1000, ncol = 2)
exact_unknown_variance_intervals <- matrix(nrow = 1000, ncol = 2)
approximate_welch_intervals <- matrix(nrow = 1000, ncol = 2)

# Цикл для симуляции 1000 раз
for (i in 1:1000) {
  # Генерируем случайные данные для двух выборок
  data1 <- rnorm(n1, mean = mean1, sd = sd)
  data2 <- rnorm(n2, mean = mean2, sd = sd)
  
  # Следующий блок кода для расчета каждого типа доверительного интервала
  
  # Асимптотический ДИ
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  z <- qnorm(0.975)
  left_a <- diff - z * diff_sd
  right_a <- diff + z * diff_sd
  asymptotic_intervals[i, ] <- c(left_a, right_a)
  
  # Точный ДИ с известной дисперсией
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd
  sd_y <- sd
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  z <- qnorm(0.975)
  left_t1 <- diff - z * diff_sd
  right_t1 <- diff + z * diff_sd
  exact_known_variance_intervals[i, ] <- c(left_t1, right_t1)
  
  # Точный ДИ с неизвестной дисперсией
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  df1 <- n1 - 1
  df2 <- n2 - 1
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  t_critical <- qt(1 - (1 - confidence_level) / 2, df1 + df2)
  left_t2 <- diff - t_critical * diff_sd
  right_t2 <- diff + t_critical * diff_sd
  exact_unknown_variance_intervals[i, ] <- c(left_t2, right_t2)
  
  # Примерный ДИ (Дисперсии не известны и не равны)
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  numerator <- ((sd_x^2 / nx) + (sd_y^2 / n2))^2
  denominator <- (sd_x^4 / (nx^2 * (nx - 1))) + (sd_y^4 / (ny^2 * (ny - 1)))
  df <- numerator / denominator
  t_critical <- qt(1 - (1 - confidence_level) / 2, df)
  left_w <- diff - t_critical * diff_sd
  right_w <- diff + t_critical * diff_sd
  approximate_welch_intervals[i, ] <- c(left_w, right_w)
}

# Выводим средние ширины интервалов для каждого типа

cat("Асимптотический ДИ                             :", mean(asymptotic_intervals[, 2] - asymptotic_intervals[, 1]), "\n")
cat("Точный ДИ с известной дисперсией               :", mean(exact_known_variance_intervals[, 2] - exact_known_variance_intervals[, 1]), "\n")
cat("Точный ДИ с неизвестной дисперсией             :", mean(exact_unknown_variance_intervals[, 2] - exact_unknown_variance_intervals[, 1]), "\n")
cat("Примерный ДИ (Дисперсии не известны и не равны):", mean(approximate_welch_intervals[, 2] - approximate_welch_intervals[, 1]), "\n")




```


### Точность ДИ

```{r}

# Воспроизведение данных
set.seed(123)

# Пример данных для двух независимых выборок
mean1 <- 20
sd <- 3
mean2 <- 20
n1 <- 10
n2 <- 10


# Инициализируем переменные для подсчета количества "ловлений" истинной разницы
asymptotic_captured <- 0
exact_known_variance_captured <- 0
exact_unknown_variance_captured <- 0
approximate_welch_captured <- 0

# Цикл для симуляции 1000 раз
for (i in 1:1000) {
  # Генерируем случайные данные для двух выборок
  data1 <- rnorm(n1, mean = mean1, sd = sd)
  data2 <- rnorm(n2, mean = mean2, sd = sd)
  
  # Следующий блок кода для расчета каждого типа доверительного интервала
  
  # Асимптотический ДИ
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  z <- qnorm(0.975)
  left_a <- diff - z * diff_sd
  right_a <- diff + z * diff_sd
  if (left_a <= 0 && right_a >= 0) {
    asymptotic_captured <- asymptotic_captured + 1
  }
  
  # Точный ДИ с известной дисперсией
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd
  sd_y <- sd
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  z <- qnorm(0.975)
  left_t1 <- diff - z * diff_sd
  right_t1 <- diff + z * diff_sd
  if (left_t1 <= 0 && right_t1 >= 0) {
    exact_known_variance_captured <- exact_known_variance_captured + 1
  }
  
  # Точный ДИ с неизвестной дисперсией
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  df1 <- n1 - 1
  df2 <- n2 - 1
  diff_sd <- sqrt(sd_x^2 / nx + sd_x^2 / ny)
  t_critical <- qt(1 - (1 - confidence_level) / 2, df1 + df2)
  left_t2 <- diff - t_critical * diff_sd
  right_t2 <- diff + t_critical * diff_sd
  if (left_t2 <= 0 && right_t2 >= 0) {
    exact_unknown_variance_captured <- exact_unknown_variance_captured + 1
  }
  
  # Примерный ДИ (Дисперсии не извеcтны и не равны)
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  numerator <- ((sd_x^2 / nx) + (sd_y^2 / n2))^2
  denominator <- (sd_x^4 / (nx^2 * (nx - 1))) + (sd_y^4 / (ny^2 * (ny - 1)))
  df <- numerator / denominator
  t_critical <- qt(1 - (1 - confidence_level) / 2, df)
  left_w <- diff - t_critical * diff_sd
  right_w <- diff + t_critical * diff_sd
  if (left_w <= 0 && right_w >= 0) {
    approximate_welch_captured <- approximate_welch_captured + 1
  }
}

# Выводим результаты
cat("Асимптотический ДИ - доля ловлений истинной разницы                             :", asymptotic_captured / 1000, "\n")
cat("Точный ДИ с известной дисперсией - доля ловлений истинной разницы               :", exact_known_variance_captured / 1000, "\n")
cat("Точный ДИ с неизвестной дисперсией - доля ловлений истинной разницы             :", exact_unknown_variance_captured / 1000, "\n")
cat("Примерный ДИ (Дисперсии не извеcтны и не равны) - доля ловлений истинной разницы:", approximate_welch_captured / 1000, "\n")


```


### Сравнительная характеристика (Asymptotic Confidence Interval, Exact Confidence Interval with Known Variances, Exact Confidence Interval with Unknown Variances, Confidence Interval by Welch в случае экспоненциального распределения (независимые группы)


### Точность ДИ

```{r}

# Воспроизведение данных
set.seed(123)

# Пример данных для двух независимых выборок
mean1 <- 20
sd <- 3
mean2 <- 20
n1 <- 10
n2 <- 10


# Инициализируем переменные для подсчета количества "ловлений" истинной разницы
asymptotic_captured <- 0
exact_known_variance_captured <- 0
exact_unknown_variance_captured <- 0
approximate_welch_captured <- 0

# Цикл для симуляции 1000 раз
for (i in 1:1000) {
  # Генерируем случайные данные для двух выборок
  #data1 <- rnorm(n1, mean = mean1, sd = sd)
  #data2 <- rnorm(n2, mean = mean2, sd = sd)
  data1 <- random_numbers <- rexp(n1, rate = 1/mean1)
  data2 <- random_numbers <- rexp(n2, rate = 1/mean2)
  
  # Следующий блок кода для расчета каждого типа доверительного интервала
  
  # Асимптотический ДИ
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  z <- qnorm(0.975)
  left_a <- diff - z * diff_sd
  right_a <- diff + z * diff_sd
  if (left_a <= 0 && right_a >= 0) {
    asymptotic_captured <- asymptotic_captured + 1
  }
  
  # Точный ДИ с известной дисперсией
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  #sd_x <- sd_x+1 # sd для такого распределения
  #sd_y <- sd_y+1 # sd для такого распределения
  sd_x <- round(sd_x, 0) # sd для такого распределения
  sd_y <- round(sd_y, 0) # sd для такого распределения
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  z <- qnorm(0.975)
  left_t1 <- diff - z * diff_sd
  right_t1 <- diff + z * diff_sd
  if (left_t1 <= 0 && right_t1 >= 0) {
    exact_known_variance_captured <- exact_known_variance_captured + 1
  }
  
  # Точный ДИ с неизвестной дисперсией
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  df1 <- n1 - 1
  df2 <- n2 - 1
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  t_critical <- qt(1 - (1 - confidence_level) / 2, df1 + df2)
  left_t2 <- diff - t_critical * diff_sd
  right_t2 <- diff + t_critical * diff_sd
  if (left_t2 <= 0 && right_t2 >= 0) {
    exact_unknown_variance_captured <- exact_unknown_variance_captured + 1
  }
  
  # Примерный ДИ (Дисперсии не извеcтны и не равны)
  x <- data1
  y <- data2
  diff <- mean(x) - mean(y)
  nx <- length(x)
  ny <- length(y)
  sd_x <- sd(x)
  sd_y <- sd(y)
  diff_sd <- sqrt(sd_x^2 / nx + sd_y^2 / ny)
  numerator <- ((sd_x^2 / nx) + (sd_y^2 / n2))^2
  denominator <- (sd_x^4 / (nx^2 * (nx - 1))) + (sd_y^4 / (ny^2 * (ny - 1)))
  df <- numerator / denominator
  t_critical <- qt(1 - (1 - confidence_level) / 2, df)
  left_w <- diff - t_critical * diff_sd
  right_w <- diff + t_critical * diff_sd
  if (left_w <= 0 && right_w >= 0) {
    approximate_welch_captured <- approximate_welch_captured + 1
  }
}

# Выводим результаты
cat("Асимптотический ДИ - доля ловлений истинной разницы                             :", asymptotic_captured / 1000, "\n")
cat("Точный ДИ с известной дисперсией - доля ловлений истинной разницы               :", exact_known_variance_captured / 1000, "\n")
cat("Точный ДИ с неизвестной дисперсией - доля ловлений истинной разницы             :", exact_unknown_variance_captured / 1000, "\n")
cat("Примерный ДИ (Дисперсии не извеcтны и не равны) - доля ловлений истинной разницы:", approximate_welch_captured / 1000, "\n")




```


## Доверительный интервал для разницы средних (независимые выборки)

### Точный ДИ (Дисперсия неизвеcтна аналогично одинарной средней, статистика Стьюдента - распределение t)



# Доверительный интервал для доли

## Wald Interval  https://towardsdatascience.com/five-confidence-intervals-for-proportions-that-you-should-know-about-7ff5484c024f


```{r}

waldInterval <- function(x, n, conf.level = 0.95){
 p <- x/n
 sd <- sqrt(p*((1-p)/n))
 z <-  qnorm(c( (1 - conf.level)/2, 1 - (1-conf.level)/2)) #returns the value of thresholds at which conf.level has to be cut at. for 95% CI, this is -1.96 and +1.96
 ci <- p + z*sd
 return(ci)
 }
#example
waldInterval(x = 20, n =40) #this will return 0.345 and 0.655

```

```{r}

numSamples <- 50 #number of samples to be drawn from population
numTrials <- 1000 #this is the sample size (size of each sample)
probs <- seq(0.001, 0.999, 0.01) #true proportions in prevalence. #for each value in this array, we will construct 95% confidence #intervals
coverage <- as.numeric() #initializing an empty vector to store coverage for each of the probs defined above
for (i in 1:length(probs)) {
 x <- rbinom(n = numSamples, size=numTrials, prob = probs[i]) #taken #n random samples and get the number of successes in each of the n #samples. thus x here will have a length equal to n
 isCovered <- as.numeric() #a boolean vector to denote if the true #population proportion (probs[i]) is covered within the constructed ci
 #since we have n different x here, we will have n different ci for #each of them. 
 for (j in 1:numSamples) {
 ci <- waldInterval(x = x[j], n = numTrials)
 isCovered[j] <- (ci[1] < probs[i]) & (probs[i] < ci[2]) #if the #true proportion (probs[i]) is covered within the constructed CI, #then it returns 1, else 0
 }
 coverage[i] <- mean(isCovered)*100 #captures the coverage for each #of the true proportions. ideally, for a 95% ci, this should be more #or else 95%
}


plot(probs, coverage, type='l', ylim = c(75,100), col='blue', lwd=2, frame.plot = FALSE, yaxt='n', main = 'Coverage of Wald Interval',
 xlab = 'True Proportion (Population Proportion) ', ylab = 'Coverage (%) for 95% CI')
abline(h = 95, lty=3, col='maroon', lwd=2)
axis(side = 2, at=seq(75,100, 5))


```


## Clopper — Pearson Interval (Exact Interval)

```{r}

numSamples <- 100 #number of samples to be drawn from population
numTrials <- 1000 #this is the sample size (size of each sample)
probs <- seq(0.001, 0.999, 0.01) #true proportions in prevalence. #for each value in this array, we will construct 95% confidence #intervals
coverage <- as.numeric() #initializing an empty vector to store coverage for each of the probs defined above
for (i in 1:length(probs)) {
 x <- rbinom(n = numSamples, size=numTrials, prob = probs[i]) #taken #n random samples and get the number of successes in each of the n #samples. thus x here will have a length equal to n
 isCovered <- as.numeric() #a boolean vector to denote if the true #population proportion (probs[i]) is covered within the constructed ci
 #since we have n different x here, we will have n different ci for #each of them. 
 for (j in 1:numSamples) {
 ci <- binom.test(x = x[j], n = numTrials)$conf
 isCovered[j] <- (ci[1] < probs[i]) & (probs[i] < ci[2]) #if the #true proportion (probs[i]) is covered within the constructed CI, #then it returns 1, else 0
 }
 coverage[i] <- mean(isCovered)*100 #captures the coverage for each #of the true proportions. ideally, for a 95% ci, this should be more #or else 95%
}
plot(probs, coverage, type='l', ylim = c(75,100), col='blue', lwd=2, frame.plot = FALSE, yaxt='n', main = 'Coverage of Clopper — Pearson',
 xlab = 'True Proportion (Population Proportion) ', ylab = 'Coverage (%) for 95% CI')
abline(h = 95, lty=3, col='maroon', lwd=2)
axis(side = 2, at=seq(75,100, 5))



```






```{r}

# Создайте данные для двух групп (количество успешных и общее количество в каждой группе)
successes_group_A <- 45
total_group_A <- 100
successes_group_B <- 60
total_group_B <- 100

# Оцените доли успешных событий в каждой группе
prop_success_A <- successes_group_A / total_group_A
prop_success_B <- successes_group_B / total_group_B

# Оцените разницу в долях
prop_diff <- prop_success_A - prop_success_B

# Задайте уровень доверия (например, 95%)
confidence_level <- 0.95

# Вычислите стандартную ошибку разницы долей
se_diff <- sqrt((prop_success_A * (1 - prop_success_A) / total_group_A) + (prop_success_B * (1 - prop_success_B) / total_group_B))

# Вычислите критические значения Z для выбранного уровня доверия
alpha <- 1 - confidence_level
z_critical <- qnorm(1 - alpha / 2)

# Вычислите границы доверительного интервала для разницы долей
margin_of_error <- z_critical * se_diff
conf_interval <- prop_diff + c(-margin_of_error, margin_of_error)

# Выведите результаты
cat("Разница долей:", prop_diff, "\n")
cat(paste("Доверительный интервал (", 100 * confidence_level, "%): [", conf_interval[1], ", ", conf_interval[2], "]\n"))



```







# Доверительный интервал для разницы долей (зависимые и независимые выборки)

```{r}
#https://www.codecamp.ru/blog/confidence-interval-in-r/

#input sample sizes and sample proportions
n1 <- 100
p1 <- .62

n2 <- 100
p2 <- .46

#calculate margin of error
margin <- qnorm(0.975)*sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)

#calculate lower and upper bounds of confidence interval
low <- (p1-p2) - margin
low

high <- (p1-p2) + margin
high


#https://rpubs.com/AllaT/conf-ints ДОБАВИТЬ !!!!

```


# Односторонние доверительные интервалы (исследования неменьшей эффективности или превосходства)

```{r}

sample_size <- 100 # Количество пациентов, прошедших, терапию

Hg_improve <- 20 # Истинное среднее изменение уровня Hg (в ГЕНЕРАЛЬНОЙ СОВОКУПНОСТИ)

Hg_sd <- 6 # Разброс в улучшении Hg

Hg_change <- rnorm(sample_size, 
                   mean = Hg_improve, 
                   sd = Hg_sd) # На сколько изменился Hg у пациентов?

# Меряем, на сколько изменилось давление после терапии:
result <- t.test(Hg_change, 
                 conf.level = 0.95)

print('Двусторонний ДИ:')
print(result)

result <- t.test(Hg_change, 
                 conf.level = 0.95, 
                 alternative = 'greater')
print('Односторонний ДИ:')
print(result)

# Попробуйте правосторонний ДИ:

result <- t.test(Hg_change, 
                 conf.level = 0.95, 
                 alternative = 'less')
print('Односторонний ДИ:')
print(result)


```



```{r}

# Install and load the necessary libraries if not already installed
# install.packages("shiny")
# install.packages("ggplot2")
library(shiny)
library(ggplot2)

# Define the UI for the Shiny app
ui <- fluidPage(
  titlePanel("Interactive Normal Distribution Density Plot and CDF with Confidence Intervals"),
  
  sidebarLayout(
    sidebarPanel(
      sliderInput("mean", "Mean:", min = -5, max = 5, value = 0, step = 0.1),
      sliderInput("sd", "Standard Deviation:", min = 0.1, max = 3, value = 1, step = 0.1),
      numericInput("quantile_lower", "Lower Quantile:", min = 0, max = 1, value = 0.025, step = 0.001),
      numericInput("quantile_upper", "Upper Quantile:", min = 0, max = 1, value = 0.975, step = 0.001),
      numericInput("x_value", "Calculate PDF/CDF at X:", min = -10, max = 10, value = 0, step = 0.1),
      textOutput("quantile_difference"),
      textOutput("pdf_value"),
      textOutput("cdf_value")
    ),
    
    mainPanel(
      plotOutput("densityPlot")
    )
  )
)

# Define a function to calculate ideal PDF values
calculateIdealPDF <- function(x, mean, sd) {
  pdf_values <- dnorm(x, mean = mean, sd = sd)
  return(pdf_values)
}

# Define the server logic for the Shiny app
server <- function(input, output) {
  
  # Create a reactive expression for calculating pdf_values
  pdf_values <- reactive({
    # Generate a range of x-values
    x_range <- seq(-10, 10, by = 0.1)
    
    # Calculate ideal PDF values using the function
    pdf_values <- calculateIdealPDF(x_range, input$mean, input$sd)
    return(pdf_values)
  })
  
  
  
  output$densityPlot <- renderPlot({
    # Generate a larger sample of data for smoother plot
    #data <- rnorm(100000, mean = input$mean, sd = input$sd)
    #x_range <- seq(-10, 10, by = 0.1)
    
    pdf_values_data <- pdf_values()
    
    
    #browser()
    # Calculate quantile values
    quant_lower <- quantile(pdf_values_data, input$quantile_lower)
    quant_upper <- quantile(pdf_values_data, input$quantile_upper)
    
    # Create a density plot with customized text size and font
    plot <- ggplot(data.frame(x = seq(-10, 10, by = 0.1), y = pdf_values_data), aes(x = x, y = pdf)) +
      geom_density(fill = "blue", color = "black", alpha = 0.5) +
      geom_vline(xintercept = quant_lower, linetype = "dashed", color = "red") +
      geom_vline(xintercept = quant_upper, linetype = "dashed", color = "green") 
      geom_vline(xintercept = input$x_value, linetype = "dotted", color = "purple") +  # Add vertical line for X
      geom_text(
        aes(x = input$x_value, y = 0.2),
        label = paste("X =", input$x_value),
        hjust = -0.2,
        size = 4
      ) +
      labs(
        title = "Smoothed Density Plot of Normal Distribution",
        x = "Value",
        y = "Density",
        caption = paste(
          "Lower Quantile:", round(quant_lower, 2),
          "\nUpper Quantile:", round(quant_upper, 2)
        )
      ) +
      theme_minimal() +  # You can change the theme if you prefer
      theme(
        text = element_text(size = 16),  # Adjust text size as needed
        plot.title = element_text(size = 20, face = "bold"),  # Title font size and style
        axis.title = element_text(size = 18),  # Axis labels font size
        axis.text = element_text(size = 14)  # Tick labels font size
      )

    # Calculate the PDF value at the specified x value
    pdf_value <- dnorm(input$x_value, mean = input$mean, sd = input$sd)
    
    # Calculate the CDF value at the specified x value
    cdf_value <- pnorm(input$x_value, mean = input$mean, sd = input$sd)
    
    # Print the PDF and CDF values
    print(plot)
    print(paste("PDF at X:", round(pdf_value, 4)))
    print(paste("CDF at X:", round(cdf_value, 4)))
  })
  
  output$quantile_difference <- renderText({
    # Calculate the difference between upper and lower quantiles
    diff_quantiles <- input$quantile_upper - input$quantile_lower
    paste("Quantile Difference:", round(diff_quantiles, 2))
  })
  
  output$pdf_value <- renderText({
    # Calculate the PDF value at the specified x value
    pdf_value <- dnorm(input$x_value, mean = input$mean, sd = input$sd)
    paste("PDF at X:", round(pdf_value, 4))
  })
  
  output$cdf_value <- renderText({
    # Calculate the CDF value at the specified x value
    cdf_value <- pnorm(input$x_value, mean = input$mean, sd = input$sd)
    paste("CDF at X:", round(cdf_value, 4))
  })
}

# Run the Shiny app
shinyApp(ui, server)

```



# Доверительный интервал для OR (отношение шансов)
# https://search.r-project.org/CRAN/refmans/epitools/html/oddsratio.html


```{r}

library(epitools)

tapw <- c("Lowest", "Highest")
outc <- c("Case", "Control")	
dat <- matrix(c(2, 35, 64, 12),2,2,byrow=TRUE)
dimnames(dat) <- list("Tap water exposure" = tapw, "Outcome" = outc)
oddsratio(dat, rev="c")       # 82.43028 21.28935 595.7773
oddsratio.midp(dat, rev="r")  # 82.43028 21.28935 595.7773
oddsratio.fisher(dat, rev="r")# 87.66286 18.69007 865.8814
oddsratio.wald(dat, rev="r")  # 93.33333 19.75797 440.891
oddsratio.small(dat, rev="r") # 57.4359 17.74042 302.6301

```



```{r, warning=FALSE}



# Создайте 2x2 таблицу данных для анализа
# Замените эти значения своими собственными данными
table_data <- matrix(c(9, 1, 1, 9), nrow = 2)

# Добавьте имена строк и столбцов для ясности
rownames(table_data) <- c("Группа A", "Группа B")
colnames(table_data) <- c("Успех", "Неудача")

# Создайте 2x2 таблицу сопряженности
contingency_table <- as.table(table_data)

# Рассчитайте отношение шансов и доверительные интервалы с использованием различных методов
# 'midp' для оценки по методу медианных несмещенных оценок (mid-p)
# 'fisher' для условной оценки максимального правдоподобия (Fisher)
# 'wald' для безусловной оценки максимального правдоподобия (Wald)
# 'small' для коррекции для малых выборок
result_midp <- oddsratio.midp(contingency_table)
result_fisher <- oddsratio.fisher(contingency_table)
result_wald <- oddsratio.wald(contingency_table)
result_small <- oddsratio.small(contingency_table)

# Вывести результаты
cat("Отношение шансов (mid-p):", result_midp$measure[2], "\n")
cat("Доверительный интервал (mid-p):", result_midp$measure[4], result_midp$measure[6], "\n")
cat("ширина Доверительного интервала (mid-p):", result_midp$measure[6] - result_midp$measure[4], "\n\n")


cat("Отношение шансов (Fisher):", result_fisher$measure[2], "\n")
cat("Доверительный интервал (Fisher):", result_fisher$measure[4], result_fisher$measure[6], "\n")
cat("ширина Доверительного интервала (Fisher):", result_fisher$measure[6] - result_fisher$measure[4], "\n\n")

cat("Отношение шансов (Wald):", result_wald$measure[2], "\n")
cat("Доверительный интервал (Wald):", result_wald$measure[4], result_wald$measure[6], "\n")
cat("ширина Доверительного интервала (Wald):", result_wald$measure[6] - result_wald$measure[4], "\n\n")

cat("Отношение шансов (коррекция для малых выборок):", result_small$measure[2], "\n")
cat("Доверительный интервал (коррекция для малых выборок):", result_small$measure[4], result_small$measure[6], "\n")
cat("ширина Доверительного интервала (коррекция для малых выборок):", result_small$measure[6] - result_small$measure[4], "\n\n")


# Каждый из методов для оценки отношения шансов (odds ratio) и доверительных интервалов имеет свои особенности и подходит для разных сценариев. Давайте рассмотрим принцип каждого метода и ситуации, когда их лучше использовать:
# 
# Медианные несмещенные оценки (Mid-P):
# 
# Принцип: Метод Mid-P использует оценку на основе медианных несмещенных оценок, которая особенно полезна, когда у вас есть небольшие выборки и неравномерное распределение данных.
# Когда использовать: Используйте метод Mid-P, когда у вас маленькие выборки или данные имеют смещенное распределение. Этот метод менее чувствителен к выбросам.
# Условная оценка максимального правдоподобия (Fisher):
# 
# Принцип: Метод Fisher использует условную оценку максимального правдоподобия и подходит для малых выборок. Он основан на точных тестах.
# Когда использовать: Используйте метод Fisher, когда у вас маленькие выборки, и вы хотите точные оценки. Этот метод особенно полезен, когда общее число наблюдений невелико.
# Безусловная оценка максимального правдоподобия (Wald):
# 
# Принцип: Метод Wald использует безусловную оценку максимального правдоподобия и является асимптотическим методом. Он подходит для больших выборок.
# Когда использовать: Используйте метод Wald, когда у вас большие выборки, и вы хотите быстрые оценки. Он может быть менее точным для малых выборок, и его использование требует, чтобы выборки были достаточно большими для асимптотической аппроксимации.
# Коррекция для малых выборок (Small Sample Adjustment):
# 
# Принцип: Этот метод корректирует оценки для малых выборок и учитывает асимптотические предположения о распределении.
# Когда использовать: Используйте коррекцию для малых выборок, когда у вас маленькие выборки и вы хотите учесть асимптотические предположения. Он может предоставить более точные оценки в сравнении с методом Wald для малых выборок.
# Выбор метода зависит от размера выборки и распределения данных. Важно оценивать, какие из методов лучше подходят для ваших конкретных данных и целей анализа. В некоторых случаях также может быть полезным сравнивать результаты, полученные разными методами, чтобы оценить их стабильность и согласованность.



```





```{r}

# Define the values from your contingency table
a <- 30  # Number of observations in Group 1 with Outcome 1
b <- 20  # Number of observations in Group 2 with Outcome 1
c <- 10  # Number of observations in Group 1 with Outcome 2
d <- 40  # Number of observations in Group 2 with Outcome 2

# Calculate the odds ratio (OR)
OR <- (a / c) / (b / d)

# Calculate the standard error (SE) of ln(OR)
SE <- sqrt((1 / a) + (1 / b) + (1 / c) + (1 / d))

# Set the confidence level (e.g., 95%)
confidence_level <- 0.95

# Calculate the critical value (Z) for the confidence interval
Z <- qnorm(1 - (1 - confidence_level) / 2)

# Calculate the lower and upper limits of the confidence interval for ln(OR)
LL <- log(OR) - (Z * SE)
UL <- log(OR) + (Z * SE)

# Calculate the confidence interval for OR
OR_CI <- exp(c(LL, UL))

# Print the results
cat("Odds Ratio (OR):", OR, "\n")
cat("Confidence Interval (95%) for OR:", OR_CI[1], "to", OR_CI[2], "\n")


```


```{r}

# Define the values from your contingency table
a <- 30  # Number of observations in Group 1 with Outcome 1
b <- 20  # Number of observations in Group 2 with Outcome 1
c <- 10  # Number of observations in Group 1 with Outcome 2
d <- 40  # Number of observations in Group 2 with Outcome 2

# Create a 2x2 contingency table
contingency_table <- matrix(c(a, b, c, d), nrow = 2)
rownames(contingency_table) <- c("Outcome 1", "Outcome 2")
colnames(contingency_table) <- c("Group 1", "Group 2")

# Perform Fisher's exact test to calculate OR and its exact confidence interval
fisher_result <- fisher.test(contingency_table, alternative = "two.sided", conf.int = TRUE)

# Extract the OR and its exact confidence interval
OR <- fisher_result$estimate
OR_CI <- fisher_result$conf.int

# Print the results
cat("Odds Ratio (OR):", OR, "\n")
cat("Exact Confidence Interval for OR:", OR_CI[1], "to", OR_CI[2], "\n")


```


```{r}

# Load the boot package
library(boot)

# Define your data
a <- 30  # Number of observations in Group 1 with Outcome 1
b <- 20  # Number of observations in Group 2 with Outcome 1
c <- 10  # Number of observations in Group 1 with Outcome 2
d <- 40  # Number of observations in Group 2 with Outcome 2

# Define a function to calculate the OR
calculate_OR <- function(data, indices) {
  sampled_data <- data[indices, ]
  a <- sum(sampled_data$Outcome == "Outcome1" & sampled_data$Group == "Group1")
  b <- sum(sampled_data$Outcome == "Outcome1" & sampled_data$Group == "Group2")
  c <- sum(sampled_data$Outcome == "Outcome2" & sampled_data$Group == "Group1")
  d <- sum(sampled_data$Outcome == "Outcome2" & sampled_data$Group == "Group2")
  
  OR <- (a / c) / (b / d)
  return(OR)
}



# Create a data frame with your data
data <- data.frame(
  Group = c(rep("Group1", a + c), rep("Group2", b + d)),
  Outcome = c(rep("Outcome1", a), rep("Outcome2", c), rep("Outcome1", b), rep("Outcome2", d))
)

# Set the number of bootstrap samples
n_bootstrap_samples <- 1000

# Perform bootstrapping to calculate the CI for OR
boot_results <- boot(data, statistic = calculate_OR, R = n_bootstrap_samples)

# Calculate the CI
OR_CI <- boot.ci(boot_results, type = "bca")

# Print the results
print(OR_CI)


```


```{r}

# Load necessary libraries
library(boot)


# Define a function to calculate asymptotic CI for OR
calculate_asymptotic_CI <- function(data, confidence_level) {
  # Implement the calculation of asymptotic CI for OR
  # Replace the following lines with your actual code
  OR <- calculate_OR(data)  # Calculate OR using your method
  SE <- calculate_SE(data)  # Calculate standard error of ln(OR)
  z <- qnorm(1 - (1 - confidence_level) / 2)
  lower_limit <- log(OR) - z * SE
  upper_limit <- log(OR) + z * SE
  return(c(exp(lower_limit), exp(upper_limit)))  # Return CI as a numeric vector
}

calculate_asymptotic_CI(simulated_data, confidence_level)


# Define a function to calculate exact CI for OR
calculate_exact_CI <- function(data, confidence_level) {
  # Implement the calculation of exact CI for OR
  # Replace the following lines with your actual code
  OR <- calculate_OR(data)  # Calculate OR using your method
  # Add code to perform exact calculation of CI
  return(c(lower_limit, upper_limit))  # Return CI as a numeric vector
}

# Define a function to calculate bootstrap CI for OR
calculate_bootstrap_CI <- function(data, confidence_level) {
  # Implement the calculation of bootstrap CI for OR
  # Replace the following lines with your actual code
  OR <- calculate_OR(data)  # Calculate OR using your method
  # Add code to perform bootstrap calculation of CI
  return(c(lower_limit, upper_limit))  # Return CI as a numeric vector
}

# Rest of the simulation code remains the same




# Define a function to generate simulated data
generate_data <- function(n, p, OR) {
  a <- round(n * p)
  c <- n - a
  b <- round(a / OR)
  d <- c - b
  
  # Create a 2x2 contingency table
  contingency_table <- matrix(c(a, b, c, d), nrow = 2)
  rownames(contingency_table) <- c("Outcome 1", "Outcome 2")
  colnames(contingency_table) <- c("Group 1", "Group 2")
  
  return(contingency_table)
}

# Set simulation parameters
n_simulations <- 1000  # Number of simulations
n_samples <- 100       # Sample size in each simulation
true_OR <- 2           # True odds ratio to simulate
confidence_level <- 0.95

# Initialize storage for results
results <- data.frame(Method = character(n_simulations), 
                       Coverage = numeric(n_simulations))

# Run simulations
for (i in 1:n_simulations) {
  # Generate simulated data
  simulated_data <- generate_data(n_samples, 0.5, true_OR)
  
  # Calculate CIs using different methods
  asymptotic_CI <- calculate_asymptotic_CI(simulated_data, confidence_level)
  exact_CI <- calculate_exact_CI(simulated_data, confidence_level)
  bootstrap_CI <- calculate_bootstrap_CI(simulated_data, confidence_level)
  
  # Determine which method provided the true OR within the CI
  asymptotic_coverage <- (asymptotic_CI[1] <= true_OR) & (true_OR <= asymptotic_CI[2])
  exact_coverage <- (exact_CI[1] <= true_OR) & (true_OR <= exact_CI[2])
  bootstrap_coverage <- (bootstrap_CI[1] <= true_OR) & (true_OR <= bootstrap_CI[2])
  
  # Store results
  if (asymptotic_coverage) {
    results[i, ] <- c("Asymptotic", 1)
  } else if (exact_coverage) {
    results[i, ] <- c("Exact", 1)
  } else if (bootstrap_coverage) {
    results[i, ] <- c("Bootstrap", 1)
  } else {
    results[i, ] <- c("None", 0)
  }
}

# Calculate coverage probabilities
coverage_probabilities <- table(results$Method) / n_simulations

# Print coverage probabilities
print(coverage_probabilities)


```



```{r}

calculate_asymptotic_CI <- function(contingency_table, confidence_level = 0.95) {
  # Calculate the odds ratio (OR) from the contingency table
  a <- contingency_table[1, 1]
  b <- contingency_table[1, 2]
  c <- contingency_table[2, 1]
  d <- contingency_table[2, 2]
  
  OR <- (a * d) / (b * c)
  
  # Calculate the standard error (SE) of the log(OR)
  SE_log_OR <- sqrt((1/a) + (1/b) + (1/c) + (1/d))
  
  # Calculate the z-score for the specified confidence level
  z <- qnorm(1 - (1 - confidence_level) / 2)
  
  # Calculate the lower and upper limits of the asymptotic CI
  lower_limit <- log(OR) - z * SE_log_OR
  upper_limit <- log(OR) + z * SE_log_OR
  
  # Transform the limits back to the OR scale
  asymptotic_CI <- exp(c(lower_limit, upper_limit))
  
  return(asymptotic_CI)
}

# Example usage:
# Create a 2x2 contingency table
contingency_table <- matrix(c(30, 20, 10, 40), nrow = 2)
rownames(contingency_table) <- c("Outcome 1", "Outcome 2")
colnames(contingency_table) <- c("Group 1", "Group 2")

# Calculate asymptotic CI for OR with a 95% confidence level
asymptotic_CI <- calculate_asymptotic_CI(contingency_table)
print(asymptotic_CI)


```






#__________________________________________________________

# Проверка статистических гипотез


```{r}
#https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/

#https://analyse-it.com/docs/user-guide/101/estimation

#https://analyse-it.com/docs/user-guide/101/exact-asymptotic-p-values#:~:text=A%20p%2Dvalue%20calculated%20using,about%20the%20hypothesis%20of%20interest.


#https://statistics.laerd.com/statistical-guides/mann-whitney-u-test-assumptions.php#:~:text=Assumption%20%234%3A%20You%20must%20determine,shape%20or%20a%20different%20shape. Mann Withney
x <- c(5,  5,  5,  4)
y <- c(0, 0, 0, 0)
wilcox.test(x, y, paired = FALSE, alternative = "greater")





```


# Chi squared with bootstrap

```{r}
#https://search.r-project.org/CRAN/refmans/DCluster/html/achisq.boot.html

install.packages('spdep')
install.packages('DCluster')

library(boot)
library(spdep)
library(DCluster)

data(nc.sids)

sids<-data.frame(Observed=nc.sids$SID74)
sids<-cbind(sids, Expected=nc.sids$BIR74*sum(nc.sids$SID74)/sum(nc.sids$BIR74))

niter<-1000

# Define the achisq.boot statistic function
# achisq.boot <- function(data, indices) {
#   observed <- data$Observed[indices]
#   expected <- data$Expected[indices]
#   chi_square <- sum((observed - expected)^2 / expected)
#   return(chi_square)
# }


#Permutation  model
chq.perboot<-boot(sids, statistic=achisq.boot, R=niter)
plot(chq.perboot)#Display results

#Multinomial model
chq.mboot<-boot(sids, statistic=achisq.pboot, sim="parametric", ran.gen=multinom.sim,  R=niter)
plot(chq.mboot)#Display results

#Poisson model
chq.pboot<-boot(sids, statistic=achisq.pboot, sim="parametric", ran.gen=poisson.sim,  R=niter)
plot(chq.pboot)#Display results

#Poisson-Gamma model
chq.pgboot<-boot(sids, statistic=achisq.pboot, sim="parametric", ran.gen=negbin.sim, R=niter)
plot(chq.pgboot)#Display results


```

```{r}

#https://livebook.manning.com/book/r-in-action/chapter-12/1 - permutation and bootstrepping

#https://www.rdocumentation.org/packages/RDS/versions/0.8-1/topics/bootstrap.contingency.test

# https://www.tandfonline.com/doi/full/10.1080/10543406.2014.920851?scroll=top&needAccess=true


if(!require('RDS')) {
    install.packages('RDS')
    library('RDS')
}

data(faux)

bootstrap.contingency.test(rds.data=faux, row.var="X", col.var="Y",
  number.of.bootstrap.samples=1000, verbose=FALSE)

data(faux)
convergence.plot(faux,c("X","Y"))




```


```{r}

install.packages("boot")



```




```{r}

waldInterval <- function(x, n, conf.level = 0.95){
 p <- x/n
 sd <- sqrt(p*((1-p)/n))
 z <- qnorm(c( (1 - conf.level)/2, 1 - (1-conf.level)/2)) #returns the value of thresholds at which conf.level has to be cut at. for 95% CI, this is -1.96 and +1.96
 ci <- p + z*sd
 return(ci)
 }
#example
waldInterval(x = 20, n =40) #this will return 0.345 and 0.655


numSamples <- 10000 #number of samples to be drawn from population
numTrials <- 100 #this is the sample size (size of each sample)

probs <- seq(0.001, 0.999, 0.01) #true proportions in prevalence. #for each value in this array, we will construct 95% confidence #intervals
coverage <- as.numeric() #initializing an empty vector to store coverage for each of the probs defined above
for (i in 1:length(probs)) {
 x <- rbinom(n = numSamples, size=numTrials, prob = probs[i]) #taken #n random samples and get the number of successes in each of the n #samples. thus x here will have a length equal to n
 isCovered <- as.numeric() #a boolean vector to denote if the true #population proportion (probs[i]) is covered within the constructed ci
 #since we have n different x here, we will have n different ci for #each of them. 
 for (j in 1:numSamples) {
 ci <- binom.test(x = x[j], n = numTrials)$conf
 isCovered[j] <- (ci[1] < probs[i]) & (probs[i] < ci[2]) #if the #true proportion (probs[i]) is covered within the constructed CI, #then it returns 1, else 0
 }
 coverage[i] <- mean(isCovered)*100 #captures the coverage for each #of the true proportions. ideally, for a 95% ci, this should be more #or else 95%
}



# Create the plot
plot(probs, coverage, type="l", ylim = c(75,100), col="blue", lwd=2, frame.plot = FALSE, yaxt='n', main = "Coverage of Wald Interval",
     xlab = "True Proportion (Population Proportion)", ylab = "Coverage (%) for 95% CI")
abline(h = 95, lty=3, col="maroon", lwd=2)
axis(side = 2, at=seq(75,100, 5))
     



```



```{r}



# Define your data
SCALE_1 <- c(3, 5, 5, 4, 4, 3, 4, 2, 2, 3, 2, 1, 1, 2, 0, 2, 5, 4, 5, 4, 0, 0, 0, 0)
SCALE_2 <- c(2, 2, 3, 2, 2, 1, 2, 3, 2, 1, 1, 2, 2, 1, 1, 1, 3, 3, 2, 3, 0, 0, 0, 0)


# Create a data frame with your data
my_data_frame <- data.frame(SCALE_1 = SCALE_1, SCALE_2 = SCALE_2)
print(my_data_frame)

my_data_frame$SCALE_1 <- factor(my_data_frame$SCALE_1, levels = c(0, 1, 2, 3, 4, 5), labels = c("Изменений нет",
                                                                                                "Единичные", 
                                                                                                "Кольцо 1 слой",
                                                                                                "Кольцо 2 слоя",
                                                                                                "Кольцо 3 слоя",
                                                                                                "Кольцо 4 и > слоёв"))

my_data_frame$SCALE_2 <- factor(my_data_frame$SCALE_2, levels = c(0, 1, 2, 3), labels = c("Изменений нет",
                                                                                       "Лёгкая", 
                                                                                       "Умеренная",
                                                                                       "Выраженная"))

# Print the data frame
print(my_data_frame)

df3 <- my_data_frame %>% 
  group_by(SCALE_1, SCALE_2) %>% 
  tally() %>% 
  complete(SCALE_2, fill = list(n = 0)) %>% 
  mutate(percentage = n / sum(n) * 100)


ggplot(df3, aes(SCALE_1, percentage, fill = SCALE_2)) + 
  geom_bar(stat = 'identity', position = 'dodge') +
  ylim(0, 100)+
  ylab("%")+
  scale_fill_brewer(palette = "Set2")+
  theme(legend.position = "right", axis.text.x = element_text(angle = 45, hjust = 1))




# 1. convert the data as a table
dt <- as.matrix(table(my_data_frame$SCALE_1, my_data_frame$SCALE_2))
dt

#dt
# 2. Graph
#balloonplot(t(dt), xlab ="", ylab="",
#            label = FALSE, 
#            repel = TRUE,
#            show.margins = FALSE)

chisq <- chisq.test(dt)
chisq

res.ca <- FactoMineR::CA(dt, graph = FALSE)
# inspect results of the CA
#print(res.ca)
eig.val <- get_eigenvalue(res.ca)
eig.val

# repel= TRUE to avoid text overlapping (slow if many point)
fviz_ca_biplot(res.ca, 
               repel = TRUE,
               col.row = "orange",
               col.col = "darkgray")

```




```{r}

library(ggplot2)

# Set a seed for reproducibility
set.seed(123)

# Generate synthetic data with a Pearson correlation of 0.85
correlation <- 0.85
n <- 100  # Number of data points

# Generate IL1 and TNF variables
IL1 <- rnorm(n)
TNF <- correlation * IL1 + sqrt(1 - correlation^2) * rnorm(n)

# Create a data frame
data <- data.frame(IL1, TNF)

# Calculate the Pearson correlation coefficient
pearson_corr <- cor(data$IL1, data$TNF)

# Create a scatter plot with increased font size
ggplot(data, aes(x = IL1, y = TNF)) +
  geom_point() +
  labs(title = paste("Pearson Correlation =", round(pearson_corr, 2))) +
  theme(
    text = element_text(size = 12),  # Adjust the font size
    axis.text.x = element_text(size = 12),  # Adjust x-axis label font size
    axis.text.y = element_text(size = 12),  # Adjust y-axis label font size
    plot.title = element_text(size = 14)  # Adjust title font size
  )

```



```{r}


# Load the required libraries
library(ggplot2)

# Sample data with a U-shaped relationship
x <- seq(-2, 2, length.out = 100)
y <- x^2 + rnorm(100)
data <- data.frame(X = x, Y = y)

# Create a scatter plot
ggplot(data, aes(x = X, y = Y)) +
  geom_point() +
  labs(x = "X-axis", y = "Y-axis", title = "Scatter Plot of a U-Shaped Relationship")



```



```{r}

# Load the required libraries
library(ggplot2)

# Fictitious preclinical research data with a U-shaped relationship
dose <- seq(-2, 2, length.out = 100)  # Dose levels
response <- x^2 + rnorm(100)  # Response with a U-shaped pattern

data <- data.frame(Dose = dose, Response = response)

# Create a scatter plot
ggplot(data, aes(x = Dose, y = Response)) +
  geom_point() +
  labs(x = "Dose", y = "Response", title = "Scatter Plot of Dose vs. Response (U-Shaped Relationship)")


correlation <- cor(data$Dose, data$Response)


ggplot(data, aes(x = Dose, y = Response)) +
  geom_point() +
  labs(x = "Dose", y = "Response", title = "Scatter Plot of Dose vs. Response (U-Shaped Relationship)") +
  annotate("text", x = 0, y = max(data$Response), 
           label = paste("Pearson Correlation =", round(correlation, 2)), 
           hjust = 0, vjust = 1)

```


# 95% conf interval for  OR 

```{r}

# Install and load the Epi package
if (!requireNamespace("Epi", quietly = TRUE)) {
  install.packages("Epi")
}

library(Epi)

# Create a vector of sample sizes ranging from 10 to 100 with a step of 5
sample_sizes <- seq(10, 100, by = 5)

# Set the number of bootstrap iterations
num_bootstraps <- 1000

# Create an empty data frame to store the results
results_df <- data.frame(SampleSize = numeric(0),
                         OR = numeric(0),
                         CI_exact_lower = numeric(0),
                         CI_exact_upper = numeric(0),
                         CI_bootstrap_lower = numeric(0),
                         CI_bootstrap_upper = numeric(0))

# Loop through each sample size and odds ratio and calculate confidence intervals
for (sample_size in sample_sizes) {
  for (or_value in odds_ratios) {
    # Set the exposure and outcome counts based on the sample size
    exposure_cases <- sample_size * 0.5
    exposure_controls <- sample_size * 0.5
    outcome_cases <- sample_size * 0.25
    outcome_controls <- sample_size * 0.25

    # Create a 2x2 table
    tab <- matrix(c(outcome_cases, outcome_controls, exposure_cases, exposure_controls), nrow = 2)

    # Calculate odds ratio and perform exact test
    or_result <- epi.2by2(tab, conf.level = 0.95, method = "exact")

    # Calculate bootstrap confidence intervals
    boot_results <- boot.epi.2by2(tab, B = num_bootstraps)

    # Append the results to the data frame
    results_df <- rbind(results_df, data.frame(
      SampleSize = sample_size,
      OR = or_value,
      CI_exact_lower = or_result$measure$measure[1],
      CI_exact_upper = or_result$measure$measure[3],
      CI_bootstrap_lower = quantile(boot_results$or, (1 - 0.95) / 2),
      CI_bootstrap_upper = quantile(boot_results$or, 1 - (1 - 0.95) / 2)
    ))
  }
}

# View the results
print(results_df)






```


